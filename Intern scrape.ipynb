{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e99acf-e452-4110-8412-8cde5ce6c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "link=\"https://sourcing.alibaba.com/rfq/rfq_search_list.htm?spm=a2700.8073608.1998677541.1.82be65aaoUUItC&country=AE&recently=Y&tracelog=newest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0f3981-9cd4-46fd-b92e-24ac3171a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup # its helps in scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511b52d1-09fd-4a15-a635-499a98d8e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=requests.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ff60df-24df-410c-97ff-44ae5fdc29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "html=res.text #it save the html page of the web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63a56ef-de91-4fb7-9a50-0b7bc63e9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=requests.get(link)\n",
    "soup =BeautifulSoup(res.text,'html.parser')# to convert text into html code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e68e0a-02d5-4b78-97f6-ea8164a155e9",
   "metadata": {},
   "source": [
    "## For titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0746bceb-d03e-453a-a93d-b8b8f5a21357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Flatbed Die Cutter\n",
      "2. Mens Sneakers 2025-Running Shoes for Men\n",
      "3. Summer Fashion Letter Loose Printed Round Neck Heavyweight Cotton Trendy Couple Short Sleeve Top T-shirt Men's Top\n",
      "4. Custom Balcony Enclosure \n",
      "5. Shape Sorter Wooden Toy For Toddlers Wooden Shape Color Sorting Preschool Stacking Blocks Toddler ...\n",
      "6. TOP Printable PP Waterproof Self-adhesive Glossy Matte Decal Paper Sheet for Inkjet Laser Printer A4 Vinyl Label Sticker Paper\n",
      "7. 4 Flavors Strawberry Lip Balm \n",
      "8. business bags and tissue paper with logo\n",
      "9. Shoe box storage\n",
      "10. OEM Hard Water Repair Moisturizing and anti-hair loss Sun protection repair Oil-controlling,fluffy ...\n",
      "11. Best Led Replacement High Power Ip68 Mini Waterproof Car H4 Led Headlight Bulb H6 Motorcycle\n",
      "12. Original 13 Inch LCD for MacBook Pro Air M1 A2338 A2337 A1706 A1708 A1989 A2289 A2251 A2159 A2179 A...\n",
      "13. For Ultra Bee Rear Brake System Kit Customize Rear Brakes Pump Assembly Spare Parts\n",
      "14. For Mazda MX5 Roaster Miata NC1 2 3 RE Style Vented Hood\n",
      "15. used engine\n",
      "16. 3 years warranty Lexu_s LS460 Industrial grade Lexu_s LS460 Industrial grade hand tool OEM customized Lexu_s LS460 OEM customize\n",
      "17. Aluminum Alloy Exhaust Pipes\n",
      "18. Vibration Motor\n",
      "19. Raw unprocessed single donor human hair\n",
      "20. Puma Ferrari Running and Walking Shoes\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://sourcing.alibaba.com/rfq/rfq_search_list.htm?country=AE&recently=Y&page=1\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Let JS load\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "# Find and print titles\n",
    "titles = []\n",
    "for tag in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "    title = tag.get(\"title\")\n",
    "    if title:\n",
    "        titles.append(title)\n",
    "\n",
    "for i, t in enumerate(titles[], 1):\n",
    "    print(f\"{i}. {t}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1df2e67a-8f61-47f2-806b-a0afb37b68fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flatbed Die Cutter',\n",
       " 'Mens Sneakers 2025-Running Shoes for Men',\n",
       " \"Summer Fashion Letter Loose Printed Round Neck Heavyweight Cotton Trendy Couple Short Sleeve Top T-shirt Men's Top\",\n",
       " 'Custom Balcony Enclosure ',\n",
       " 'Shape Sorter Wooden Toy For Toddlers Wooden Shape Color Sorting Preschool Stacking Blocks Toddler ...',\n",
       " 'TOP Printable PP Waterproof Self-adhesive Glossy Matte Decal Paper Sheet for Inkjet Laser Printer A4 Vinyl Label Sticker Paper',\n",
       " '4 Flavors Strawberry Lip Balm ',\n",
       " 'business bags and tissue paper with logo',\n",
       " 'Shoe box storage',\n",
       " 'OEM Hard Water Repair Moisturizing and anti-hair loss Sun protection repair Oil-controlling,fluffy ...',\n",
       " 'Best Led Replacement High Power Ip68 Mini Waterproof Car H4 Led Headlight Bulb H6 Motorcycle',\n",
       " 'Original 13 Inch LCD for MacBook Pro Air M1 A2338 A2337 A1706 A1708 A1989 A2289 A2251 A2159 A2179 A...',\n",
       " 'For Ultra Bee Rear Brake System Kit Customize Rear Brakes Pump Assembly Spare Parts',\n",
       " 'For Mazda MX5 Roaster Miata NC1 2 3 RE Style Vented Hood',\n",
       " 'used engine',\n",
       " '3 years warranty Lexu_s LS460 Industrial grade Lexu_s LS460 Industrial grade hand tool OEM customized Lexu_s LS460 OEM customize',\n",
       " 'Aluminum Alloy Exhaust Pipes',\n",
       " 'Vibration Motor',\n",
       " 'Raw unprocessed single donor human hair',\n",
       " 'Puma Ferrari Running and Walking Shoes']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f3b01-0d6a-4496-ba58-a46127902c5b",
   "metadata": {},
   "source": [
    "## For buyer Name and image link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4759406c-f0ad-4293-94b0-f634ce75246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://sourcing.alibaba.com/rfq/rfq_search_list.htm?country=AE&recently=Y&page=1\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Let JS load\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "# Buyerimagelink=[]\n",
    "# for tag in soup.find_all(\"img\", class_=\"img\"):\n",
    "#     blink= tag.get(\"src\")\n",
    "#     if blink:\n",
    "#         Buyerimagelink.append(blink)\n",
    "#     else:\n",
    "#         Buyerimagelink.append(\"Nan\")\n",
    "Buyerimagelink = []\n",
    "buyer_blocks = soup.find_all(\"div\", class_=\"avatar\")\n",
    "\n",
    "for block in buyer_blocks:\n",
    "    img_tag = block.find(\"img\")\n",
    "    if img_tag and img_tag.get(\"src\"):\n",
    "        Buyerimagelink.append(img_tag.get(\"src\"))\n",
    "    else:\n",
    "        # No image, try to find initial-based avatar\n",
    "        initial_tag = block.find(\"span\") or block.find(\"div\")\n",
    "        if initial_tag:\n",
    "            Buyerimagelink.append(initial_tag.text.strip())\n",
    "        else:\n",
    "            Buyerimagelink.append(\"NaN\")\n",
    "\n",
    "        \n",
    "Buyname=[]\n",
    "for tag in soup.find_all(\"div\", class_=\"text\"):\n",
    "    bname= tag.text\n",
    "    if bname:\n",
    "        Buyname.append(bname)\n",
    "\n",
    "# Find and print titles\n",
    "titles = []\n",
    "for tag in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "    title = tag.get(\"title\")\n",
    "    if title:\n",
    "        titles.append(title)\n",
    "\n",
    "# for i, t in enumerate(titles[], 1):\n",
    "#     print(f\"{i}. {t}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6705389-fd91-4fe0-a050-06da780b73dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M',\n",
       " 'M',\n",
       " 'S',\n",
       " 'D',\n",
       " '//ae01.alicdn.com/kf/A64cb6709e46e4a83be09bead4ee8950e7.jpg_50x50.jpg',\n",
       " 'T',\n",
       " 'O',\n",
       " 'S',\n",
       " 'S',\n",
       " 'H',\n",
       " 'L',\n",
       " 'I',\n",
       " 'L',\n",
       " 'Y',\n",
       " 'M',\n",
       " 'A',\n",
       " 'A',\n",
       " 'M',\n",
       " 'S',\n",
       " 'S']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Buyerimagelink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8bdb22c5-275b-4668-8fb4-90e694252972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mahmoud AlGendy',\n",
       " 'Mohamed Ali',\n",
       " 'sajid hussain',\n",
       " 'DonEricson Nova',\n",
       " 'Khozema Zaki',\n",
       " 'Taimoor Nisar',\n",
       " 'Osama Shkosh',\n",
       " 'Saif Almazrooei',\n",
       " 'sattar ahmad',\n",
       " 'hamad saeed',\n",
       " 'lya adl',\n",
       " 'ilham alrashdi',\n",
       " 'Luqman Kasana',\n",
       " 'Yuga Chari',\n",
       " 'moath hamed',\n",
       " 'Ahmed Alhasmi',\n",
       " 'abdulla buyer',\n",
       " 'Mohamed Makki',\n",
       " 'Shadeb Ghalib',\n",
       " 'samir samir']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Buyname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9aac1-2ff5-41da-8b35-9d8f01856089",
   "metadata": {},
   "source": [
    "## For inquiry Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5170c43-ced9-4e49-853b-353146332b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://sourcing.alibaba.com/rfq/rfq_search_list.htm?country=AE&recently=Y&page=1\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Let JS load\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "# Buyerimagelink=[]\n",
    "# for tag in soup.find_all(\"img\", class_=\"img\"):\n",
    "#     blink= tag.get(\"src\")\n",
    "#     if blink:\n",
    "#         Buyerimagelink.append(blink)\n",
    "#     else:\n",
    "#         Buyerimagelink.append(\"Nan\")\n",
    "inquirytime=[]\n",
    "for time in soup.find_all(\"div\",class_=\"brh-rfq-item__publishtime\"):\n",
    "    intime=time.text\n",
    "    if intime:\n",
    "        inquirytime.append(intime)\n",
    "    \n",
    "Buyerimagelink = []\n",
    "buyer_blocks = soup.find_all(\"div\", class_=\"avatar\")\n",
    "\n",
    "for block in buyer_blocks:\n",
    "    img_tag = block.find(\"img\")\n",
    "    if img_tag and img_tag.get(\"src\"):\n",
    "        Buyerimagelink.append(img_tag.get(\"src\"))\n",
    "    else:\n",
    "        # No image, try to find initial-based avatar\n",
    "        initial_tag = block.find(\"span\") or block.find(\"div\")\n",
    "        if initial_tag:\n",
    "            Buyerimagelink.append(initial_tag.text.strip())\n",
    "        else:\n",
    "            Buyerimagelink.append(\"NaN\")\n",
    "\n",
    "        \n",
    "Buyname=[]\n",
    "for tag in soup.find_all(\"div\", class_=\"text\"):\n",
    "    bname= tag.text\n",
    "    if bname:\n",
    "        Buyname.append(bname)\n",
    "\n",
    "# Find and print titles\n",
    "titles = []\n",
    "for tag in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "    title = tag.get(\"title\")\n",
    "    if title:\n",
    "        titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71a0c85f-a04d-4b24-9e57-b9489aa39b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date Posted:11 minutes before',\n",
       " 'Date Posted:21 minutes before',\n",
       " 'Date Posted:50 minutes before',\n",
       " 'Date Posted:56 minutes before',\n",
       " 'Date Posted:1 hours before',\n",
       " 'Date Posted:2 hours before',\n",
       " 'Date Posted:2 hours before',\n",
       " 'Date Posted:5 hours before',\n",
       " 'Date Posted:5 hours before',\n",
       " 'Date Posted:6 hours before',\n",
       " 'Date Posted:6 hours before',\n",
       " 'Date Posted:7 hours before',\n",
       " 'Date Posted:8 hours before',\n",
       " 'Date Posted:8 hours before',\n",
       " 'Date Posted:8 hours before',\n",
       " 'Date Posted:8 hours before',\n",
       " 'Date Posted:8 hours before',\n",
       " 'Date Posted:8 hours before',\n",
       " 'Date Posted:9 hours before',\n",
       " 'Date Posted:9 hours before']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inquirytime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3fa61a-d0ea-423b-94cf-35dbd96fd53f",
   "metadata": {},
   "source": [
    "## For Quotes left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84ef655f-26c3-4beb-9322-926ffd02a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://sourcing.alibaba.com/rfq/rfq_search_list.htm?country=AE&recently=Y&page=1\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Let JS load\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "# Buyerimagelink=[]\n",
    "# for tag in soup.find_all(\"img\", class_=\"img\"):\n",
    "#     blink= tag.get(\"src\")\n",
    "#     if blink:\n",
    "#         Buyerimagelink.append(blink)\n",
    "#     else:\n",
    "#         Buyerimagelink.append(\"Nan\")\n",
    "qleft=[]\n",
    "for left in soup.find_all(\"div\",class_='brh-rfq-item__quote-left'):\n",
    "    x=left.find(\"span\").text\n",
    "    if x :\n",
    "        qleft.append(x)\n",
    "    \n",
    "inquirytime=[]\n",
    "for time in soup.find_all(\"div\",class_=\"brh-rfq-item__publishtime\"):\n",
    "    intime=time.text\n",
    "    if intime:\n",
    "        inquirytime.append(intime)\n",
    "    \n",
    "Buyerimagelink = []\n",
    "buyer_blocks = soup.find_all(\"div\", class_=\"avatar\")\n",
    "\n",
    "for block in buyer_blocks:\n",
    "    img_tag = block.find(\"img\")\n",
    "    if img_tag and img_tag.get(\"src\"):\n",
    "        Buyerimagelink.append(img_tag.get(\"src\"))\n",
    "    else:\n",
    "        # No image, try to find initial-based avatar\n",
    "        initial_tag = block.find(\"span\") or block.find(\"div\")\n",
    "        if initial_tag:\n",
    "            Buyerimagelink.append(initial_tag.text.strip())\n",
    "        else:\n",
    "            Buyerimagelink.append(\"NaN\")\n",
    "\n",
    "        \n",
    "Buyname=[]\n",
    "for tag in soup.find_all(\"div\", class_=\"text\"):\n",
    "    bname= tag.text\n",
    "    if bname:\n",
    "        Buyname.append(bname)\n",
    "\n",
    "# Find and print titles\n",
    "titles = []\n",
    "for tag in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "    title = tag.get(\"title\")\n",
    "    if title:\n",
    "        titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22858db6-dcb1-4779-92c1-ea386b152269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7',\n",
       " '7',\n",
       " '10',\n",
       " '10',\n",
       " '7',\n",
       " '9',\n",
       " '9',\n",
       " '9',\n",
       " '7',\n",
       " '4',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '7',\n",
       " '6',\n",
       " '9',\n",
       " '10',\n",
       " '10',\n",
       " '10',\n",
       " '10']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qleft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de48ee2-418f-4787-a3f7-447ab713519c",
   "metadata": {},
   "source": [
    "## For Country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9d102f2e-aee1-465e-8c10-abef406ca5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brh-rfq-item__country-flag\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://sourcing.alibaba.com/rfq/rfq_search_list.htm?country=AE&recently=Y&page=1\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Let JS load\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "cname = []\n",
    "for name in soup.find_all(\"div\", class_=\"brh-rfq-item__country\"):\n",
    "    fname=name.text[11:]\n",
    "    cname.append(fname)\n",
    "\n",
    "qleft=[]\n",
    "for left in soup.find_all(\"div\",class_='brh-rfq-item__quote-left'):\n",
    "    x=left.find(\"span\").text\n",
    "    if x :\n",
    "        qleft.append(x)\n",
    "    \n",
    "inquirytime=[]\n",
    "for time in soup.find_all(\"div\",class_=\"brh-rfq-item__publishtime\"):\n",
    "    intime=time.text\n",
    "    if intime:\n",
    "        inquirytime.append(intime)\n",
    "    \n",
    "Buyerimagelink = []\n",
    "buyer_blocks = soup.find_all(\"div\", class_=\"avatar\")\n",
    "\n",
    "for block in buyer_blocks:\n",
    "    img_tag = block.find(\"img\")\n",
    "    if img_tag and img_tag.get(\"src\"):\n",
    "        Buyerimagelink.append(img_tag.get(\"src\"))\n",
    "    else:\n",
    "        # No image, try to find initial-based avatar\n",
    "        initial_tag = block.find(\"span\") or block.find(\"div\")\n",
    "        if initial_tag:\n",
    "            Buyerimagelink.append(initial_tag.text.strip())\n",
    "        else:\n",
    "            Buyerimagelink.append(\"NaN\")\n",
    "\n",
    "        \n",
    "Buyname=[]\n",
    "for tag in soup.find_all(\"div\", class_=\"text\"):\n",
    "    bname= tag.text\n",
    "    if bname:\n",
    "        Buyname.append(bname)\n",
    "\n",
    "# Find and print titles\n",
    "titles = []\n",
    "for tag in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "    title = tag.get(\"title\")\n",
    "    if title:\n",
    "        titles.append(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8038d5-bc98-4dfa-b411-e2dcda7e7514",
   "metadata": {},
   "source": [
    "## For Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "41fa2219-4ce4-4743-9e1f-904db1794a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brh-rfq-item__quantity-num\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://sourcing.alibaba.com/rfq/rfq_search_list.htm?country=AE&recently=Y&page=1\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Let JS load\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "quantity=[]\n",
    "for quant in soup.find_all(\"span\", class_=\"brh-rfq-item__quantity-num\"):\n",
    "    quanti=quant.text+\"Piece/Pieces\"\n",
    "    quantity.append(quanti)\n",
    "\n",
    "cname = []\n",
    "for name in soup.find_all(\"div\", class_=\"brh-rfq-item__country\"):\n",
    "    fname=name.text[11:]\n",
    "    cname.append(fname)\n",
    "\n",
    "qleft=[]\n",
    "for left in soup.find_all(\"div\",class_='brh-rfq-item__quote-left'):\n",
    "    x=left.find(\"span\").text\n",
    "    if x :\n",
    "        qleft.append(x)\n",
    "    \n",
    "inquirytime=[]\n",
    "for time in soup.find_all(\"div\",class_=\"brh-rfq-item__publishtime\"):\n",
    "    intime=time.text\n",
    "    if intime:\n",
    "        inquirytime.append(intime)\n",
    "    \n",
    "Buyerimagelink = []\n",
    "buyer_blocks = soup.find_all(\"div\", class_=\"avatar\")\n",
    "\n",
    "for block in buyer_blocks:\n",
    "    img_tag = block.find(\"img\")\n",
    "    if img_tag and img_tag.get(\"src\"):\n",
    "        Buyerimagelink.append(img_tag.get(\"src\"))\n",
    "    else:\n",
    "        # No image, try to find initial-based avatar\n",
    "        initial_tag = block.find(\"span\") or block.find(\"div\")\n",
    "        if initial_tag:\n",
    "            Buyerimagelink.append(initial_tag.text.strip())\n",
    "        else:\n",
    "            Buyerimagelink.append(\"NaN\")\n",
    "\n",
    "        \n",
    "Buyname=[]\n",
    "for tag in soup.find_all(\"div\", class_=\"text\"):\n",
    "    bname= tag.text\n",
    "    if bname:\n",
    "        Buyname.append(bname)\n",
    "\n",
    "# Find and print titles\n",
    "titles = []\n",
    "for tag in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "    title = tag.get(\"title\")\n",
    "    if title:\n",
    "        titles.append(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9bceea-4d99-463d-aa0f-1394a7308428",
   "metadata": {},
   "source": [
    "## For email confirmed,Typically replies ,Complete Order via RFQ ,Interactive User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b00a8300-409a-4b43-a98b-6b682fa52e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "# \n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://sourcing.alibaba.com/rfq/rfq_search_list.htm?country=AE&recently=Y&page=1\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Let JS load\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "Emconf=[]\n",
    "Typrep=[]\n",
    "EXPbuyer=[]\n",
    "comord=[]\n",
    "IntUser=[]\n",
    "i=0\n",
    "for t in soup.find_all(\"div\", class_=\"bc-brh-rfq-flag bc-brh-rfq-flag--buyer\"):\n",
    "    tags = [i.text.strip() for i in t.find_all(\"div\", class_=\"next-tag\")]\n",
    "    if tags:\n",
    "        Emconf.append(\"Yes\" if \"Email Confirmed\" in tags else \"No\")\n",
    "        EXPbuyer.append(\"Yes\" if \"Experienced buyer\" in tags else \"No\")\n",
    "        Typrep.append(\"Yes\" if \"Typically replies\" in tags else \"No\")\n",
    "        comord.append(\"Yes\" if \"Complete order via RFQ\" in tags else \"No\")\n",
    "        IntUser.append(\"Yes\" if \"Interactive User\" in tags else \"No\")\n",
    "        i+=1\n",
    "    if(len(tags)==0):\n",
    "        Emconf.append(\"No\")\n",
    "        EXPbuyer.append(\"No\")\n",
    "        Typrep.append(\"No\")\n",
    "        comord.append(\"No\")\n",
    "        IntUser.append(\"No\")\n",
    "while(i!=20):\n",
    "        Emconf.append(\"No\")\n",
    "        EXPbuyer.append(\"No\")\n",
    "        Typrep.append(\"No\")\n",
    "        comord.append(\"No\")\n",
    "        IntUser.append(\"No\")\n",
    "        i+=1\n",
    "quantity=[]\n",
    "for quant in soup.find_all(\"span\", class_=\"brh-rfq-item__quantity-num\"):\n",
    "    quanti=quant.text+\"Piece/Pieces\"\n",
    "    quantity.append(quanti)\n",
    "\n",
    "cname = []\n",
    "for name in soup.find_all(\"div\", class_=\"brh-rfq-item__country\"):\n",
    "    fname=name.text[11:]\n",
    "    cname.append(fname)\n",
    "\n",
    "qleft=[]\n",
    "for left in soup.find_all(\"div\",class_='brh-rfq-item__quote-left'):\n",
    "    x=left.find(\"span\").text\n",
    "    if x :\n",
    "        qleft.append(x)\n",
    "    \n",
    "inquirytime=[]\n",
    "for time in soup.find_all(\"div\",class_=\"brh-rfq-item__publishtime\"):\n",
    "    intime=time.text\n",
    "    if intime:\n",
    "        inquirytime.append(intime)\n",
    "    \n",
    "Buyerimagelink = []\n",
    "buyer_blocks = soup.find_all(\"div\", class_=\"avatar\")\n",
    "\n",
    "for block in buyer_blocks:\n",
    "    img_tag = block.find(\"img\")\n",
    "    if img_tag and img_tag.get(\"src\"):\n",
    "        Buyerimagelink.append(img_tag.get(\"src\"))\n",
    "    else:\n",
    "        # No image, try to find initial-based avatar\n",
    "        initial_tag = block.find(\"span\") or block.find(\"div\")\n",
    "        if initial_tag:\n",
    "            Buyerimagelink.append(initial_tag.text.strip())\n",
    "        else:\n",
    "            Buyerimagelink.append(\"NaN\")\n",
    "\n",
    "        \n",
    "Buyname=[]\n",
    "for tag in soup.find_all(\"div\", class_=\"text\"):\n",
    "    bname= tag.text\n",
    "    if bname:\n",
    "        Buyname.append(bname)\n",
    "\n",
    "# Find and print titles\n",
    "titles = []\n",
    "for tag in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "    title = tag.get(\"title\")\n",
    "    if title:\n",
    "        titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "34f4ca11-4a5c-4487-9e9a-ec7a0029cf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Emconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a2e80eda-d950-4840-bfbb-3ae48a23d69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IntUser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a0ec72-3a2d-49fc-bd75-a165b011132e",
   "metadata": {},
   "source": [
    "## For inquiry Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7600aa79-a834-43d7-b620-d7f8d9099f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brh-rfq-item__subject-link\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "# \n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://sourcing.alibaba.com/rfq/rfq_search_list.htm?country=AE&recently=Y&page=1\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Let JS load\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "inlink=[]\n",
    "for link in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "    a=link.get(\"href\")\n",
    "    inlink.append(a)\n",
    "    # break\n",
    "Emconf=[]\n",
    "Typrep=[]\n",
    "EXPbuyer=[]\n",
    "comord=[]\n",
    "IntUser=[]\n",
    "i=0\n",
    "for t in soup.find_all(\"div\", class_=\"bc-brh-rfq-flag bc-brh-rfq-flag--buyer\"):\n",
    "    tags = [i.text.strip() for i in t.find_all(\"div\", class_=\"next-tag\")]\n",
    "    if tags:\n",
    "        Emconf.append(\"Yes\" if \"Email Confirmed\" in tags else \"No\")\n",
    "        EXPbuyer.append(\"Yes\" if \"Experienced buyer\" in tags else \"No\")\n",
    "        Typrep.append(\"Yes\" if \"Typically replies\" in tags else \"No\")\n",
    "        comord.append(\"Yes\" if \"Complete order via RFQ\" in tags else \"No\")\n",
    "        IntUser.append(\"Yes\" if \"Interactive User\" in tags else \"No\")\n",
    "        i+=1\n",
    "    if(len(tags)==0):\n",
    "        Emconf.append(\"No\")\n",
    "        EXPbuyer.append(\"No\")\n",
    "        Typrep.append(\"No\")\n",
    "        comord.append(\"No\")\n",
    "        IntUser.append(\"No\")\n",
    "while(i!=20):\n",
    "        Emconf.append(\"No\")\n",
    "        EXPbuyer.append(\"No\")\n",
    "        Typrep.append(\"No\")\n",
    "        comord.append(\"No\")\n",
    "        IntUser.append(\"No\")\n",
    "        i+=1\n",
    "quantity=[]\n",
    "for quant in soup.find_all(\"span\", class_=\"brh-rfq-item__quantity-num\"):\n",
    "    quanti=quant.text+\"Piece/Pieces\"\n",
    "    quantity.append(quanti)\n",
    "\n",
    "cname = []\n",
    "for name in soup.find_all(\"div\", class_=\"brh-rfq-item__country\"):\n",
    "    fname=name.text[11:]\n",
    "    cname.append(fname)\n",
    "\n",
    "qleft=[]\n",
    "for left in soup.find_all(\"div\",class_='brh-rfq-item__quote-left'):\n",
    "    x=left.find(\"span\").text\n",
    "    if x :\n",
    "        qleft.append(x)\n",
    "    \n",
    "inquirytime=[]\n",
    "for time in soup.find_all(\"div\",class_=\"brh-rfq-item__publishtime\"):\n",
    "    intime=time.text\n",
    "    if intime:\n",
    "        inquirytime.append(intime)\n",
    "    \n",
    "Buyerimagelink = []\n",
    "buyer_blocks = soup.find_all(\"div\", class_=\"avatar\")\n",
    "\n",
    "for block in buyer_blocks:\n",
    "    img_tag = block.find(\"img\")\n",
    "    if img_tag and img_tag.get(\"src\"):\n",
    "        Buyerimagelink.append(img_tag.get(\"src\"))\n",
    "    else:\n",
    "        # No image, try to find initial-based avatar\n",
    "        initial_tag = block.find(\"span\") or block.find(\"div\")\n",
    "        if initial_tag:\n",
    "            Buyerimagelink.append(initial_tag.text.strip())\n",
    "        else:\n",
    "            Buyerimagelink.append(\"NaN\")\n",
    "\n",
    "        \n",
    "Buyname=[]\n",
    "for tag in soup.find_all(\"div\", class_=\"text\"):\n",
    "    bname= tag.text\n",
    "    if bname:\n",
    "        Buyname.append(bname)\n",
    "\n",
    "# Find and print titles\n",
    "titles = []\n",
    "for tag in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "    title = tag.get(\"title\")\n",
    "    if title:\n",
    "        titles.append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ce0ab1dc-0cc2-4f67-add0-4bc5406b6494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//sourcing.alibaba.com/rfq_detail.htm?p=ID1eMv8AJ05_Ag7VwY0xFBViQLVyTpFK9ue3_NB5Ir5q8Lnyr6d56nRUDnHtWhrpm9m&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1eMv8AJ05_Ag7VwY0xFBVibtyVaeSc1LJtdDMaQQ079FDVVurUb9DjZzRmKLxcYuh&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1LMeR-oQilg2GFzpXvxnVaMVKa9wM2XZHQFXQQytDUt3OVnJELxT0FHwuqHPIZJxP&language=ar_AR&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1LMeR-oQilg2GFzpXvxnVaLQ2lwulq_A5GlrHgg7sGx43ESYOfaRU4bKHNYiEz-o1&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1AdaGdx-7Rov_NN97g3xY0Nllsoam8Pkk00l6LKbEUSHtqBEQt9P1YFHxKKDFx266&language=ar_AR&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1AdaGdx-7Rov_NN97g3xY0LOhLINjsbeolwJ15LN6OOWOv-MiSzbUwVCq1J3G_iGd&language=ar_AR&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1AdaGdx-7Rov_NN97g3xY0PIloKWi13kmYvpZpdS0ZzNKKwJy_Fayd2HYf_uMFyR0&language=ar_AR&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1qlTs9o73BAj8-lfK8bRl32Npa8B1PgINy-PHQHOAjFSyv9hfH6si35_ncJ8dXoeM&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1qlTs9o73BAj8-lfK8bRl30ocoi10XNOHPESRwhE9pq4u-ZhIvIxJar-c0DRfpbVY&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1WIk75P7Sl8w67LIdK0CXfgQthBeFqX6yUbhZzCSQtJ_puzSS1_FNy4J3gDk6OTKn&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1nz2wp4CZmy2u3ncUnakGY7cMtJ5uBRGC_6SeRRaOxYPpuRyWuUYRrf4olfzkHdJN&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1nz2wp4CZmy2u3ncUnakGY79JDOcaNE3W-sk95_DyfT_tYhqgP3EV-WfHpgoeAdx9&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID18yaOsdIdQfEOvRL1dAWutWTq37MEILXYJFKNK_qKMwidC-gvvyhE_sJdeIpsBcw_&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID18yaOsdIdQfEOvRL1dAWutYlVVz9sTkBOVlPAoo_6QE0h_bmFltZnFLRt4zhM0T7I&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID18yaOsdIdQfEOvRL1dAWutTFKXpGzQXAL2N2cIHhYVjH4svaEHxCSxocHSU0vDaBK&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1MsBXc_xrxrTK2Bs_9Nfc2mSXU1HSnU93Uy8Nti9sdWZGKfb86eL816rht-4SJ1Ka&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1MsBXc_xrxrTK2Bs_9Nfc2gcBXiooVkIP1reb3qpnkH39YI2PCHD_VIgUon34JMC0&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1MsBXc_xrxrTK2Bs_9Nfc2gswkOICKRYf9zrOl5U_GDOuHLs7ePejVKHXVXxZ_Xog&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1GKxPUpEWRMMSI7IWbV26GdGkki8WkCbCDKvTLFSS9hIH09eh51KeOWfRtDWTzLy-&language=ar_AR&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject',\n",
       " '//sourcing.alibaba.com/rfq_detail.htm?p=ID1GKxPUpEWRMMSI7IWbV26Ga31Wbj26-tWaFZLZSTDvmj8ryT4lRjNrfVD0VisTORs&uuid=cbe4ea34-b051-4c71-aef3-b9493cc04f55&tracelog=sourcing_list_subject']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f2267b49-c9e2-4338-9ec7-2035231df6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inlink)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436516c7-7ab9-4451-b325-93347358e969",
   "metadata": {},
   "source": [
    "## Inquiry Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f3593a-9524-4910-a706-3099b2ccd02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [18:49<00:00, 564.54s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 126\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(titles)):\n\u001b[0;32m    124\u001b[0m     sdate\u001b[38;5;241m.\u001b[39mappend(date\u001b[38;5;241m.\u001b[39mtoday())\n\u001b[1;32m--> 126\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m: titles,\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuyer Name\u001b[39m\u001b[38;5;124m'\u001b[39m: Buyname,\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuyer image link\u001b[39m\u001b[38;5;124m'\u001b[39m:Buyerimagelink ,\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInquiry Time\u001b[39m\u001b[38;5;124m'\u001b[39m: inquirytime,\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuotes Left\u001b[39m\u001b[38;5;124m'\u001b[39m: qleft,\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m: cname,\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantity\u001b[39m\u001b[38;5;124m'\u001b[39m:  quantity,\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmail Confirmed\u001b[39m\u001b[38;5;124m'\u001b[39m: Emconf,\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTypical Replies\u001b[39m\u001b[38;5;124m'\u001b[39m:Typrep,\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInteractive User\u001b[39m\u001b[38;5;124m'\u001b[39m:IntUser,\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComplete Order via RFQ\u001b[39m\u001b[38;5;124m'\u001b[39m:comord,\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInquriy URL\u001b[39m\u001b[38;5;124m'\u001b[39m:inlink,\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInquiry Date\u001b[39m\u001b[38;5;124m'\u001b[39m: indate,\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScrapping Date\u001b[39m\u001b[38;5;124m'\u001b[39m: sdate\n\u001b[0;32m    141\u001b[0m     \n\u001b[0;32m    142\u001b[0m })\n\u001b[0;32m    143\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit() \n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Save to Excel\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "Emconf=[]\n",
    "Typrep=[]   \n",
    "EXPbuyer=[]\n",
    "comord=[]\n",
    "IntUser=[]\n",
    "quantity=[]\n",
    "cname = []\n",
    "qleft=[]\n",
    "inquirytime=[]\n",
    "Buyname=[]\n",
    "titles = []\n",
    "Buyerimagelink = []\n",
    "inlink = []\n",
    "indate = []\n",
    "# Step 1: Scrape RFQ listing page\n",
    "base = \"https://sourcing.alibaba.com/rfq/rfq_search_list.htm?country=AE&recently=Y&page=\"\n",
    "for page in tqdm(range(1,3)):# I just do for 2 pages if you want more then increase the number 3 to get more page details \n",
    "    url=base+str(page)\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for JS to load\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    #inqurylink\n",
    "    \n",
    "    for link in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "        a = \"https:\"+link.get(\"href\")\n",
    "        inlink.append(a)\n",
    "    #inquirydate\n",
    "    # Step 2: Scrape individual RFQ pages for datetime\n",
    "    \n",
    "    for i in range(min(20, len(inlink))):  # Avoid IndexError\n",
    "        url = inlink[i]\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        soup1 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        for d in soup1.find_all(\"span\", class_=\"datetime\"):\n",
    "            indate.append(d.text[:-10])\n",
    "        \n",
    "    \n",
    "    \n",
    "    #Email confirmation,Typing replies, Complete Order via RFQ,Interactive User\n",
    "    for t in soup.find_all(\"div\", class_=\"bc-brh-rfq-flag bc-brh-rfq-flag--buyer\"):\n",
    "        tags = [i.text.strip() for i in t.find_all(\"div\", class_=\"next-tag\")]\n",
    "        if tags:\n",
    "            Emconf.append(\"Yes\" if \"Email Confirmed\" in tags else \"No\")\n",
    "            EXPbuyer.append(\"Yes\" if \"Experienced buyer\" in tags else \"No\")\n",
    "            Typrep.append(\"Yes\" if \"Typically replies\" in tags else \"No\")\n",
    "            comord.append(\"Yes\" if \"Complete order via RFQ\" in tags else \"No\")\n",
    "            IntUser.append(\"Yes\" if \"Interactive User\" in tags else \"No\")\n",
    "            i+=1\n",
    "        if(len(tags)==0):\n",
    "            Emconf.append(\"No\")\n",
    "            EXPbuyer.append(\"No\")\n",
    "            Typrep.append(\"No\")\n",
    "            comord.append(\"No\")\n",
    "            IntUser.append(\"No\")\n",
    "\n",
    "    #Quantity Required\n",
    "    \n",
    "    for quant in soup.find_all(\"span\", class_=\"brh-rfq-item__quantity-num\"):\n",
    "        quanti=quant.text+\"Piece/Pieces\"\n",
    "        quantity.append(quanti)\n",
    "    #Country\n",
    "  \n",
    "    for name in soup.find_all(\"div\", class_=\"brh-rfq-item__country\"):\n",
    "        fname=name.text[11:]\n",
    "        cname.append(fname)\n",
    "    #Quotes Left\n",
    "    \n",
    "    for left in soup.find_all(\"div\",class_='brh-rfq-item__quote-left'):\n",
    "        x=left.find(\"span\").text\n",
    "        if x :\n",
    "            qleft.append(x)\n",
    "    #Inquiry Time\n",
    "    \n",
    "    for time_div in soup.find_all(\"div\",class_=\"brh-rfq-item__publishtime\"):\n",
    "        intime=time_div.text\n",
    "        if intime:\n",
    "            inquirytime.append(intime)\n",
    "    #Buyerimage link    \n",
    "  \n",
    "    buyer_blocks = soup.find_all(\"div\", class_=\"avatar\")\n",
    "    \n",
    "    for block in buyer_blocks:\n",
    "        img_tag = block.find(\"img\")\n",
    "        if img_tag and img_tag.get(\"src\"):\n",
    "            Buyerimagelink.append(img_tag.get(\"src\"))\n",
    "        else:\n",
    "            # No image, try to find initial-based avatar\n",
    "            initial_tag = block.find(\"span\") or block.find(\"div\")\n",
    "            if initial_tag:\n",
    "                Buyerimagelink.append(initial_tag.text.strip())\n",
    "            else:\n",
    "                Buyerimagelink.append(\"NaN\")\n",
    "    \n",
    "    #Buyname       \n",
    "   \n",
    "    for tag in soup.find_all(\"div\", class_=\"text\"):\n",
    "        bname= tag.text\n",
    "        if bname:\n",
    "            Buyname.append(bname)\n",
    "    \n",
    "    #Titles\n",
    "    \n",
    "    for tag in soup.find_all(\"a\", class_=\"brh-rfq-item__subject-link\"):\n",
    "        title = tag.get(\"title\")\n",
    "        if title:\n",
    "            titles.append(title)\n",
    "#Srcappind date:\n",
    "sdate=[]\n",
    "for j in range(0,len(titles)):\n",
    "    sdate.append(date.today())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Buyer Name': Buyname,\n",
    "    'Buyer image link':Buyerimagelink ,\n",
    "    'Inquiry Time': inquirytime,\n",
    "    'Quotes Left': qleft,\n",
    "    'Country': cname,\n",
    "    'Quantity':  quantity,\n",
    "    'Email Confirmed': Emconf,\n",
    "    'Typical Replies':Typrep,\n",
    "    'Interactive User':IntUser,\n",
    "    'Complete Order via RFQ':comord,\n",
    "    'Inquriy URL':inlink,\n",
    "    'Inquiry Date': indate,\n",
    "    'Scrapping Date': sdate\n",
    "    \n",
    "})\n",
    "driver.quit() \n",
    "# Save to Excel\n",
    "df.to_excel('Final.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e3ce5b4-60b6-4949-897c-49df1b270201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab964a9f-5d40-48c9-82f4-1b0e03e40c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b0170b-4152-4d88-bd66-13796724c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    comord.append(\"No\")\n",
    "    Emconf.append('No')\n",
    "    Typrep.append('No')\n",
    "    IntUser.append('No')\n",
    "    EXPbuyer.append('No')\n",
    "# Because we have none of these termns then we have return none value i put that condition but it doesn't work\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e140350b-cc9f-46df-b4b3-300f613d7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Buyer Name': Buyname,\n",
    "    'Buyer image link':Buyerimagelink ,\n",
    "    'Inquiry Time': inquirytime,\n",
    "    'Quotes Left': qleft,\n",
    "    'Country': cname,\n",
    "    'Quantity':  quantity,\n",
    "    'Email Confirmed': Emconf,\n",
    "    'Typical Replies':Typrep,\n",
    "    'Interactive User':IntUser,\n",
    "    'Complete Order via RFQ':comord,\n",
    "    'Inquriy URL':inlink,\n",
    "    'Inquiry Date': indate,\n",
    "    'Scrapping Date': sdate\n",
    "    \n",
    "})\n",
    "df.to_csv('Final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500981d-6a6c-4647-af65-eb548f937699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
